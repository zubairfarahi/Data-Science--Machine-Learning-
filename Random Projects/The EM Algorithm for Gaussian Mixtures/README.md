
# The Expectation Maximization (EM) algorithm 

The Expectation Maximization (EM) algorithm is a general iterative method to
find the maximum likelihood estimates of parameters in a statistical model. So
far, we’ve applied the EM algorithm in the context of Bayesian Networks. In
this context we were given some samples that contains Missing Completely at
Random / Missing at Random data, and our goal was to infer the parameters
of the Bayesian Network (tables of probabilities).
We’ve previously mentioned that the EM algorithm is a general method that
can be applied to a variety of other problems such as: Hidden Markov Models
and Gaussian Mixtures. In this homework we will apply the EM algorithm
to a Gaussian Mixture model, trying to infer the underling parameters of the
generative statistical model as we will further discuss



## Screenshots

![App Screenshot](Random Projects\The EM Algorithm for Gaussian Mixtures\1.PNG)

![App Screenshot](Random Projects\The EM Algorithm for Gaussian Mixtures\2.PNG)


